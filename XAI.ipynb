{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "be793c72-2836-4ac6-82ee-4f67515daebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Numerical Operations\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Text Preprocessing\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "import string\n",
    "\n",
    "# Dataset Splitting and Feature Extraction\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Model Evaluation\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Word Embedding Models\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# BioBERT Model\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# Cross validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#NB top words\n",
    "from pathlib import Path\n",
    "\n",
    "#Lime\n",
    "from lime.lime_text import LimeTextExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88ddd64e-b919-490f-b6a8-114fae524cb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Labels Preview:\n",
      "   condition_label                   condition_name\n",
      "0                1                        neoplasms\n",
      "1                2        digestive system diseases\n",
      "2                3          nervous system diseases\n",
      "3                4          cardiovascular diseases\n",
      "4                5  general pathological conditions\n",
      "\n",
      "Test Preview:\n",
      "   condition_label                                   medical_abstract\n",
      "0                3  Obstructive sleep apnea following topical orop...\n",
      "1                5  Neutrophil function and pyogenic infections in...\n",
      "2                5  A phase II study of combined methotrexate and ...\n",
      "3                1  Flow cytometric DNA analysis of parathyroid tu...\n",
      "4                4  Paraneoplastic vasculitic neuropathy: a treata...\n",
      "\n",
      "Train Preview:\n",
      "   condition_label                                   medical_abstract\n",
      "0                5  Tissue changes around loose prostheses. A cani...\n",
      "1                1  Neuropeptide Y and neuron-specific enolase lev...\n",
      "2                2  Sexually transmitted diseases of the colon, re...\n",
      "3                1  Lipolytic factors associated with murine and h...\n",
      "4                3  Does carotid restenosis predict an increased r...\n"
     ]
    }
   ],
   "source": [
    "# creating a preview of each csv\n",
    "df1 = pd.read_csv('Medical-Abstracts-TC-Corpus/medical_tc_labels.csv')\n",
    "df2 = pd.read_csv('Medical-Abstracts-TC-Corpus/medical_tc_test.csv')\n",
    "df3 = pd.read_csv('Medical-Abstracts-TC-Corpus/medical_tc_train.csv')\n",
    "\n",
    "# Preview the first few rows of each\n",
    "print(\"\\nLabels Preview:\")\n",
    "print(df1.head())\n",
    "\n",
    "print(\"\\nTest Preview:\")\n",
    "print(df2.head())\n",
    "\n",
    "print(\"\\nTrain Preview:\")\n",
    "print(df3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9072ae8f-96be-467a-9b94-470ee60bea0f",
   "metadata": {},
   "source": [
    "## Text processing\n",
    "\n",
    "First of all, a preprocessing fo the text is needed to work with more efficiency and have less issues and a better performance; in this case the operation\n",
    "that are going to be implemented to the text are the following:\n",
    "\n",
    "Lowercasing: Convert all text to lowercase to ensure uniformity.\n",
    "Tokenization: Split the text into individual words or tokens.\n",
    "Removing Stopwords: Eliminate common words like \"and,\" \"the,\" etc., that do nott add much value.\n",
    "Stemming or Lemmatization: Reduce words to their root forms.\n",
    "Removing Punctuation: Get rid of unnecessary symbols like periods, commas, etc.\n",
    "\n",
    "However we need first to install the nltk library or in this case already installed in the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dab0a6bb-c7a8-4aef-81af-b75769f095b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65cbea45-34c5-4f55-8037-6c6f3e9e6952",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to /Users/Eleve/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
      "[nltk_data] Downloading package stopwords to /Users/Eleve/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Set with Cleaned Text:\n",
      "                                    medical_abstract  \\\n",
      "0  Tissue changes around loose prostheses. A cani...   \n",
      "1  Neuropeptide Y and neuron-specific enolase lev...   \n",
      "2  Sexually transmitted diseases of the colon, re...   \n",
      "3  Lipolytic factors associated with murine and h...   \n",
      "4  Does carotid restenosis predict an increased r...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  tissu chang around loos prosthes canin model i...  \n",
      "1  neuropeptid neuron-specif enolas level benign ...  \n",
      "2  sexual transmit diseas colon rectum anu challe...  \n",
      "3  lipolyt factor associ murin human cancer cache...  \n",
      "4  carotid restenosi predict increas risk late sy...  \n",
      "\n",
      "Test Set with Cleaned Text:\n",
      "                                    medical_abstract  \\\n",
      "0  Obstructive sleep apnea following topical orop...   \n",
      "1  Neutrophil function and pyogenic infections in...   \n",
      "2  A phase II study of combined methotrexate and ...   \n",
      "3  Flow cytometric DNA analysis of parathyroid tu...   \n",
      "4  Paraneoplastic vasculitic neuropathy: a treata...   \n",
      "\n",
      "                                        cleaned_text  \n",
      "0  obstruct sleep apnea follow topic oropharyng a...  \n",
      "1  neutrophil function pyogen infect bone marrow ...  \n",
      "2  phase ii studi combin methotrex teniposid infu...  \n",
      "3  flow cytometr dna analysi parathyroid tumor im...  \n",
      "4  paraneoplast vasculit neuropathi treatabl neur...  \n"
     ]
    }
   ],
   "source": [
    "# Downloading the necessary resources to tokenize and stopwords\n",
    "nltk.download('punkt_tab', force=True)\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Initialize the stemmer and stop words\n",
    "stemmer = PorterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Here is the processing function for the text\n",
    "def preprocess_text(text):\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Tokenize the text into words\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and stopwords\n",
    "    tokens = [word for word in tokens if word not in string.punctuation and word not in stop_words]\n",
    "    \n",
    "    # Apply stemming to reduce words to their root form\n",
    "    tokens = [stemmer.stem(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Applying preprocessing to the 'medical_abstract' column in both training and test datasets\n",
    "df3['cleaned_text'] = df3['medical_abstract'].apply(preprocess_text)  # Training set\n",
    "df2['cleaned_text'] = df2['medical_abstract'].apply(preprocess_text)  # Test set\n",
    "\n",
    "# Preview the cleaned data\n",
    "print(\"\\nTraining Set with Cleaned Text:\")\n",
    "print(df3[['medical_abstract', 'cleaned_text']].head())\n",
    "\n",
    "print(\"\\nTest Set with Cleaned Text:\")\n",
    "print(df2[['medical_abstract', 'cleaned_text']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcb3e7d-969b-4fcb-b9ff-264be441102b",
   "metadata": {},
   "source": [
    "### Dataset splitting\n",
    "slip the training file(df3) because the test file will be used only at the end, the training file will be divided into 80% training and 20% validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46ce429-ef20-4c10-9546-99483f701d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6eb3cfae-7e91-42ab-b1b9-d719e5ed357e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 9240\n",
      "Validation set size: 2310\n"
     ]
    }
   ],
   "source": [
    "#Splitting the Data into Training and Validation Sets and in 2 parts each because each set has labels and input data, df3 is the training csv\n",
    "X_train, X_val, y_train, y_val = train_test_split(df3['cleaned_text'], df3['condition_label'], test_size=0.2, random_state=42)\n",
    "\n",
    "#checking if the split has worked as 80/20 \n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a583b6-05b9-435f-9ef4-fe1625809c85",
   "metadata": {},
   "source": [
    "# Bag-of-Words (TF-IDF) representation\n",
    "\n",
    "TF-IDF (Term Frequency-Inverse Document Frequency) will convert the text into numerical vectors based on the importance of each word in the corpus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f2bb390e-1929-4888-b421-5c6926f71ec8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9240, 24928)\n",
      "(2310, 24928)\n"
     ]
    }
   ],
   "source": [
    "# Create a TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit on the training set and transform both training and validation sets\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "\n",
    "# Show shape of the resulting matrices\n",
    "print(X_train_tfidf.shape)\n",
    "print(X_val_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6aaad8-fe37-4f50-886d-c52f7b7108fa",
   "metadata": {},
   "source": [
    "## Naive Bayes (Training and Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "afe0c46f-47bd-4883-899e-20fb0a521147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (TF-IDF) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.61      0.66       479\n",
      "           2       1.00      0.00      0.01       224\n",
      "           3       0.30      0.01      0.02       295\n",
      "           4       0.70      0.53      0.60       520\n",
      "           5       0.41      0.78      0.54       792\n",
      "\n",
      "    accuracy                           0.51      2310\n",
      "   macro avg       0.63      0.39      0.37      2310\n",
      "weighted avg       0.58      0.51      0.46      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Naive Bayes on the training set\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = nb_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Naive Bayes (TF-IDF) Performance:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8742b4b-5344-4a2a-a63a-c2b590994d43",
   "metadata": {},
   "source": [
    "## Top words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "00538f84-2742-4b13-8279-8e0f51c6d313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV -> figures/nb_tfidf/nb_tfidf_topwords.csv\n",
      "Saved figure -> figures/nb_tfidf/nb_tfidf_topwords_1.png\n",
      "Saved figure -> figures/nb_tfidf/nb_tfidf_topwords_2.png\n",
      "Saved figure -> figures/nb_tfidf/nb_tfidf_topwords_3.png\n",
      "Saved figure -> figures/nb_tfidf/nb_tfidf_topwords_4.png\n",
      "Saved figure -> figures/nb_tfidf/nb_tfidf_topwords_5.png\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# ------------- config -------------\n",
    "TOP_K = 10\n",
    "OUTDIR = Path(\"figures/nb_tfidf\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "CSV_PATH = OUTDIR / \"nb_tfidf_topwords.csv\"\n",
    "\n",
    "# ------------- get names & scores -------------\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "class_names = [str(c) for c in nb_model.classes_]  # e.g., ['1','2','3','4','5']\n",
    "\n",
    "# log P(term | class)\n",
    "scores = nb_model.feature_log_prob_.copy()  # shape [n_classes, n_features]\n",
    "\n",
    "\n",
    "# ------------- build a tidy table (also saved as CSV) -------------\n",
    "rows = []\n",
    "for ci, cname in enumerate(class_names):\n",
    "    ci_scores = scores[ci]\n",
    "    top_idx = np.argsort(ci_scores)[-TOP_K:][::-1]\n",
    "    for rank, j in enumerate(top_idx, start=1):\n",
    "        rows.append({\n",
    "            \"class\": cname,\n",
    "            \"rank\": rank,\n",
    "            \"term\": feature_names[j],\n",
    "            \"score\": float(ci_scores[j])\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(CSV_PATH, index=False)\n",
    "print(f\"Saved CSV -> {CSV_PATH}\")\n",
    "\n",
    "# ------------- make one plot per class -------------\n",
    "for cname in class_names:\n",
    "    sub = df[df[\"class\"] == cname].sort_values(\"score\")\n",
    "    terms = sub[\"term\"].values\n",
    "    vals  = sub[\"score\"].values\n",
    "\n",
    "    plt.figure(figsize=(7, 4))\n",
    "    plt.barh(terms, vals)\n",
    "    plt.xlabel(r\"$\\log P(\\mathrm{term}\\mid \\mathrm{class})$\")\n",
    "    plt.title(f\"Naïve Bayes (TF-IDF): Top terms — class {cname}\")\n",
    "    plt.tight_layout()\n",
    "    outpath = OUTDIR / f\"nb_tfidf_topwords_{cname}.png\"\n",
    "    plt.savefig(outpath, dpi=220)\n",
    "    plt.close()\n",
    "    print(f\"Saved figure -> {outpath}\")\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0105a208-ffc1-4fcf-be71-39adf11e0cbd",
   "metadata": {},
   "source": [
    "## Decision Tree (Training and Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ecbdd869-840d-427e-8f66-8792e26da59a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (TF-IDF) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.62      0.59       479\n",
      "           2       0.38      0.45      0.41       224\n",
      "           3       0.30      0.36      0.33       295\n",
      "           4       0.52      0.52      0.52       520\n",
      "           5       0.34      0.28      0.31       792\n",
      "\n",
      "    accuracy                           0.43      2310\n",
      "   macro avg       0.42      0.45      0.43      2310\n",
      "weighted avg       0.43      0.43      0.43      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree classifier\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = dt_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Decision Tree (TF-IDF) Performance:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b1b86b-5e7c-473a-b3a8-61275198bf6e",
   "metadata": {},
   "source": [
    "### Small decision tree for better visualization in the plot tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13f97264-e74e-4d51-aaec-c07b6edb0ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(max_depth=3, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, random_state=42)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_small = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "dt_small.fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e9afb59e-c722-4e22-9d1e-82e582f8fd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plot_tree(dt_small, feature_names=tfidf_vectorizer.get_feature_names_out(),\n",
    "          class_names=[str(c) for c in dt_model.classes_],\n",
    "          filled=True, fontsize=6)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/dt_tfidf_tree.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0c74edc-a997-40ae-8b2f-0f17c9f6a8a7",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) (Training and Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "88042da6-2f20-43ea-b701-d19c4cce6e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/svm/_classes.py:31: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (TF-IDF) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.64      0.70      0.67       479\n",
      "           2       0.45      0.46      0.46       224\n",
      "           3       0.42      0.44      0.43       295\n",
      "           4       0.61      0.61      0.61       520\n",
      "           5       0.44      0.41      0.42       792\n",
      "\n",
      "    accuracy                           0.52      2310\n",
      "   macro avg       0.51      0.52      0.52      2310\n",
      "weighted avg       0.52      0.52      0.52      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM classifier\n",
    "svm_model = LinearSVC(random_state=42)   # linear by design; has coef_\n",
    "svm_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred = svm_model.predict(X_val_tfidf)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"SVM (TF-IDF) Performance:\")\n",
    "print(classification_report(y_val, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "24c66ec2-2173-4b18-bfcf-37753ae64862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures/svm_tfidf/svm_tfidf_class1.png\n",
      "Saved figures/svm_tfidf/svm_tfidf_class2.png\n",
      "Saved figures/svm_tfidf/svm_tfidf_class3.png\n",
      "Saved figures/svm_tfidf/svm_tfidf_class4.png\n",
      "Saved figures/svm_tfidf/svm_tfidf_class5.png\n",
      "All done. Plots saved in figures/svm_tfidf\n"
     ]
    }
   ],
   "source": [
    "# feature names\n",
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "\n",
    "# Output folder\n",
    "outdir = Path(\"figures/svm_tfidf\")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def plot_top_features_svm(class_idx, top_k=10):\n",
    "    coefs = np.asarray(svm_model.coef_[class_idx]).ravel()   # ensure dense 1D array\n",
    "    top_pos = np.argsort(coefs)[-top_k:]     # most positive\n",
    "    top_neg = np.argsort(coefs)[:top_k]      # most negative\n",
    "    top_features = np.hstack([top_neg, top_pos])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = [\"red\" if w < 0 else \"blue\" for w in coefs[top_features]]\n",
    "    plt.barh(feature_names[top_features], coefs[top_features], color=colors)\n",
    "    plt.title(f\"SVM (TF–IDF): Class {class_idx+1}\")\n",
    "    plt.xlabel(\"Coefficient value\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # save inside folder\n",
    "    fname = outdir / f\"svm_tfidf_class{class_idx+1}.png\"\n",
    "    plt.savefig(fname, dpi=300)\n",
    "    plt.close()\n",
    "    print(f\"Saved {fname}\")\n",
    "\n",
    "# Generate plots for all classes\n",
    "for c in range(len(svm_model.classes_)):\n",
    "    plot_top_features_svm(c, top_k=10)\n",
    "\n",
    "print(f\"All done. Plots saved in {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a8a498-025c-4378-8ced-1357d9c02ea6",
   "metadata": {},
   "source": [
    "## Logistic Regression (Training and Evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b1a9dccd-e512-4656-80d2-f0d9fe10557f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (TF-IDF) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.77      0.73       479\n",
      "           2       0.57      0.38      0.46       224\n",
      "           3       0.52      0.38      0.44       295\n",
      "           4       0.67      0.68      0.68       520\n",
      "           5       0.49      0.55      0.52       792\n",
      "\n",
      "    accuracy                           0.59      2310\n",
      "   macro avg       0.59      0.55      0.57      2310\n",
      "weighted avg       0.59      0.59      0.58      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Train a Logistic Regression model\n",
    "logreg_model = LogisticRegression(\n",
    "    max_iter=1000, solver=\"liblinear\", multi_class=\"ovr\", random_state=42\n",
    ")\n",
    "logreg_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Step 2: Make predictions on the validation set\n",
    "y_pred_logreg = logreg_model.predict(X_val_tfidf)\n",
    "\n",
    "# Step 3: Evaluate the model's performance\n",
    "print(\"Logistic Regression (TF-IDF) Performance:\")\n",
    "logreg_report = classification_report(y_val, y_pred_logreg, output_dict=True)\n",
    "print(classification_report(y_val, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b9d10f11-4bbc-4372-9b40-367feb9c29c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved figures/lr_tfidf/lr_tfidf_class_1.png\n",
      "Saved figures/lr_tfidf/lr_tfidf_class_2.png\n",
      "Saved figures/lr_tfidf/lr_tfidf_class_3.png\n",
      "Saved figures/lr_tfidf/lr_tfidf_class_4.png\n",
      "Saved figures/lr_tfidf/lr_tfidf_class_5.png\n",
      "All LR plots saved in: figures/lr_tfidf\n"
     ]
    }
   ],
   "source": [
    "feature_names = np.array(tfidf_vectorizer.get_feature_names_out())\n",
    "class_names   = [str(c) for c in logreg_model.classes_]\n",
    "outdir = Path(\"figures/lr_tfidf\"); outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 3) Plot top +/-K features per class and save PNGs\n",
    "def plot_top_features_lr(class_idx, top_k=10):\n",
    "    coefs = np.asarray(logreg_model.coef_[class_idx]).ravel()\n",
    "    top_pos = np.argsort(coefs)[-top_k:]     # strongest positive words for this class\n",
    "    top_neg = np.argsort(coefs)[:top_k]      # strongest negative (against this class)\n",
    "    top_idx = np.hstack([top_neg, top_pos])\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = [\"tab:red\" if w < 0 else \"tab:blue\" for w in coefs[top_idx]]\n",
    "    plt.barh(feature_names[top_idx], coefs[top_idx], color=colors)\n",
    "    plt.title(f\"Logistic Regression (TF–IDF): Class {class_names[class_idx]}\")\n",
    "    plt.xlabel(\"Coefficient\")\n",
    "    plt.tight_layout()\n",
    "    fname = outdir / f\"lr_tfidf_class_{class_names[class_idx]}.png\"\n",
    "    plt.savefig(fname, dpi=300); plt.close()\n",
    "    print(f\"Saved {fname}\")\n",
    "\n",
    "for c in range(len(class_names)):\n",
    "    plot_top_features_lr(c, top_k=10)\n",
    "\n",
    "print(f\"All LR plots saved in: {outdir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21858f0-2fbc-4647-8c00-861e6c7f5772",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03168ac8-a914-42dd-b5fd-e1e4e35fd2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_nb_tfidf = cross_val_score(nb_model, X_train_tfidf, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_dt_tfidf = cross_val_score(dt_model, X_train_tfidf, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_svm_tfidf = cross_val_score(svm_model, X_train_tfidf, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_logreg_tfidf = cross_val_score(logreg_model, X_train_tfidf, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "print(\"TF-IDF Cross-Validation Accuracy:\\n\"\n",
    "      f\"Naive Bayes: {cv_scores_nb_tfidf.mean():.4f}, \"\n",
    "      f\"Decision Tree: {cv_scores_dt_tfidf.mean():.4f}, \"\n",
    "      f\"SVM: {cv_scores_svm_tfidf.mean():.4f}, \"\n",
    "      f\"Logistic Regression: {cv_scores_logreg_tfidf.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9196b08-9df7-4676-b1df-7f589b5cf098",
   "metadata": {},
   "source": [
    "## Comparison of the result with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce19ebb-a427-4b17-bc27-f01ae01b2266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model results\n",
    "results = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision (weighted avg)': [],\n",
    "    'Recall (weighted avg)': [],\n",
    "    'F1-Score (weighted avg)': []\n",
    "}\n",
    "\n",
    "# Helper function to evaluate and store model results\n",
    "def evaluate_model(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Get classification report\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the results\n",
    "    results['Model'].append(model_name)\n",
    "    results['Accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    results['Precision (weighted avg)'].append(report['weighted avg']['precision'])\n",
    "    results['Recall (weighted avg)'].append(report['weighted avg']['recall'])\n",
    "    results['F1-Score (weighted avg)'].append(report['weighted avg']['f1-score'])\n",
    "\n",
    "# 1. Multinomial Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "evaluate_model(\"Multinomial Naive Bayes\", nb_model, X_train_tfidf, y_train, X_val_tfidf, y_val)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "evaluate_model(\"Decision Tree\", dt_model, X_train_tfidf, y_train, X_val_tfidf, y_val)\n",
    "\n",
    "# 3. Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "evaluate_model(\"Support Vector Machine\", svm_model, X_train_tfidf, y_train, X_val_tfidf, y_val)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "logreg_model = LogisticRegression(random_state=42)\n",
    "evaluate_model(\"Logistic Regression\", logreg_model, X_train_tfidf, y_train, X_val_tfidf, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b61990-566a-49d8-a37e-c7440e2d2b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results dictionary into a DataFrame\n",
    "results_df_tfidf = pd.DataFrame(results)\n",
    "\n",
    "# Set up the figure for the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(results_df_tfidf.set_index('Model').T, annot=True, cmap='viridis', linewidths=0.5, fmt=\".2f\")\n",
    "plt.title('Comparison of Model Performance using TF-IDF Feature Representation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b939b15-46aa-4fa4-9404-6262b1110744",
   "metadata": {},
   "source": [
    "# Word Embeddings (Word2Vec) representation\n",
    "\n",
    "We will use the Gensim library to train a Word2Vec model and create word embeddings for the training and validation sets.\n",
    "take out the comment if gensim is not already installed in your machine\n",
    "\n",
    "check version and the inner acrchitecture of word2vec after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003e1ff2-11eb-44dc-b61a-9db23a962cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f576eae9-8e1f-4c54-8cd9-a3ea3977f687",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['tokenized_text'] = df3['cleaned_text'].apply(lambda x: x.split())\n",
    "df2['tokenized_text'] = df2['cleaned_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Train a Word2Vec model on the tokenized training data\n",
    "word2vec_model = Word2Vec(sentences=df3['tokenized_text'], vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b73983-8600-45d1-9644-03876bf2d814",
   "metadata": {},
   "source": [
    "Now that we have a trained Word2Vec model, we need to convert each document (list of words) into a single vector. This is typically done by averaging the word vectors for each word in the document, here is how to do so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "68d3a2e9-f279-427b-88c9-0d209e740937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_word2vec shape: (9240, 100)\n",
      "y_train shape: (9240,)\n",
      "X_val_word2vec shape: (2310, 100)\n",
      "y_val shape: (2310,)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Split the Data\n",
    "X_train, X_val, y_train, y_val = train_test_split(df3['cleaned_text'], df3['condition_label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 2: Tokenize the Cleaned Text for Training and Validation Sets\n",
    "X_train_tokenized = X_train.apply(lambda x: x.split())\n",
    "X_val_tokenized = X_val.apply(lambda x: x.split())\n",
    "\n",
    "# Step 3: Train a Word2Vec Model on the Tokenized Training Data\n",
    "word2vec_model = Word2Vec(sentences=X_train_tokenized, vector_size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Step 4: Generate Word2Vec Embeddings for Each Document\n",
    "def get_word2vec_embeddings(text, model):\n",
    "    vectors = [model.wv[word] for word in text if word in model.wv]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(100)  # Return a vector of zeros if the document has no known words\n",
    "\n",
    "# Apply the embedding function to the training and validation sets\n",
    "X_train_word2vec = X_train_tokenized.apply(lambda x: get_word2vec_embeddings(x, word2vec_model))\n",
    "X_val_word2vec = X_val_tokenized.apply(lambda x: get_word2vec_embeddings(x, word2vec_model))\n",
    "\n",
    "# Convert the results to NumPy arrays for use in the models\n",
    "X_train_word2vec = np.vstack(X_train_word2vec)\n",
    "X_val_word2vec = np.vstack(X_val_word2vec)\n",
    "\n",
    "# Print shapes to verify consistency\n",
    "print(\"X_train_word2vec shape:\", X_train_word2vec.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val_word2vec shape:\", X_val_word2vec.shape)\n",
    "print(\"y_val shape:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29514820-63d6-47a5-946f-ab83a5a18ec4",
   "metadata": {},
   "source": [
    "## Gaussian Naive Bayes with Word2Vec\n",
    "\n",
    "To use Naive Bayes with Word2Vec, we will use Gaussian Naive Bayes, which is designed for continuous data like the dense embeddings from Word2Vec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "41df6236-f159-48e8-bff9-1be04ce7bb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes (Word2Vec) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.62      0.70      0.66       479\n",
      "           2       0.34      0.43      0.38       224\n",
      "           3       0.31      0.59      0.41       295\n",
      "           4       0.59      0.71      0.64       520\n",
      "           5       0.45      0.18      0.25       792\n",
      "\n",
      "    accuracy                           0.48      2310\n",
      "   macro avg       0.46      0.52      0.47      2310\n",
      "weighted avg       0.49      0.48      0.46      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Gaussian Naive Bayes classifier using Word2Vec embeddings\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_gnb = gnb_model.predict(X_val_word2vec)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Gaussian Naive Bayes (Word2Vec) Performance:\")\n",
    "print(classification_report(y_val, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18abbade-a6e5-4106-a816-021c3b201321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved HTML/PNG for sample 1 (pred: 3)\n",
      "Saved HTML/PNG for sample 2 (pred: 1)\n",
      "Saved HTML/PNG for sample 3 (pred: 5)\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/nb_word2vec_lime\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "class_names = [str(c) for c in gnb_model.classes_]\n",
    "label_to_idx = {c: i for i, c in enumerate(gnb_model.classes_)}  # if you ever need true->idx\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "sample_indices = [0, 1, 2]  # pick any you like\n",
    "for i in sample_indices:\n",
    "    raw_text = X_val.iloc[i] if hasattr(X_val, \"iloc\") else X_val[i]\n",
    "\n",
    "    # 1) get predicted label index for THIS text\n",
    "    proba = predict_proba_word2vec([raw_text])[0]\n",
    "    pred_idx = int(np.argmax(proba))\n",
    "\n",
    "    # 2) ask LIME to explain that specific label\n",
    "    exp = explainer.explain_instance(\n",
    "        raw_text,\n",
    "        predict_proba_word2vec,\n",
    "        num_features=10,\n",
    "        labels=[pred_idx]          # <-- key fix\n",
    "    )\n",
    "\n",
    "    # 3) save interactive HTML\n",
    "    exp.save_to_file(str(OUTDIR / f\"nb_word2vec_lime_{i+1}.html\"))\n",
    "\n",
    "    # 4) save static PNG for the same label\n",
    "    token_weights = exp.as_list(label=pred_idx)  # use predicted label index\n",
    "    if token_weights:\n",
    "        terms, weights = zip(*token_weights)\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "        plt.xlabel(\"LIME weight (contribution to predicted class)\")\n",
    "        plt.title(f\"LIME — Word2Vec + GaussianNB (sample {i+1})\\nPredicted: {class_names[pred_idx]}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTDIR / f\"nb_word2vec_lime_{i+1}.png\", dpi=220)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Saved HTML/PNG for sample {i+1} (pred: {class_names[pred_idx]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91055cdb-a7cc-4267-8d3a-ef4d586269d3",
   "metadata": {},
   "source": [
    "## Decision Tree with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ee03369c-6ea3-4c51-9329-695e64d96e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree (Word2Vec) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.55      0.52       479\n",
      "           2       0.20      0.25      0.22       224\n",
      "           3       0.21      0.24      0.23       295\n",
      "           4       0.46      0.45      0.45       520\n",
      "           5       0.27      0.23      0.25       792\n",
      "\n",
      "    accuracy                           0.35      2310\n",
      "   macro avg       0.33      0.34      0.33      2310\n",
      "weighted avg       0.35      0.35      0.35      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Decision Tree classifier using Word2Vec embeddings\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_dt = dt_model.predict(X_val_word2vec)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Decision Tree (Word2Vec) Performance:\")\n",
    "print(classification_report(y_val, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6827afe-8909-4a50-b4b4-d0b1e1e33ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/dt_word2vec/dt_w2v_tree.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/dt_word2vec\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----- train a shallow tree for visualization\n",
    "dt_shallow = DecisionTreeClassifier(\n",
    "    max_depth=3, min_samples_split=20, min_samples_leaf=10, random_state=42\n",
    ")\n",
    "dt_shallow.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# ----- feature & class names\n",
    "d = X_train_word2vec.shape[1]                # e.g., 100\n",
    "feat_names = [f\"w2v_dim_{i}\" for i in range(d)]\n",
    "class_names = [str(c) for c in dt_shallow.classes_]\n",
    "\n",
    "# ----- plot and save the tree\n",
    "plt.figure(figsize=(14, 10))\n",
    "plot_tree(\n",
    "    dt_shallow,\n",
    "    feature_names=feat_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=True,\n",
    "    proportion=True,\n",
    "    fontsize=9,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTDIR / \"dt_w2v_tree.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved:\", OUTDIR / \"dt_w2v_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f46d40ca-e91f-4a3d-8a2f-00beb2ebcdc8",
   "metadata": {},
   "source": [
    "## Support Vector Machine (SVM) with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8fdc5d0f-ffa9-4e2a-a294-99e6ff4a3aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM (Word2Vec) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71       479\n",
      "           2       0.52      0.29      0.37       224\n",
      "           3       0.53      0.31      0.39       295\n",
      "           4       0.68      0.67      0.67       520\n",
      "           5       0.47      0.59      0.52       792\n",
      "\n",
      "    accuracy                           0.57      2310\n",
      "   macro avg       0.58      0.52      0.53      2310\n",
      "weighted avg       0.58      0.57      0.56      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train an SVM classifier using Word2Vec embeddings\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_pred_svm = svm_model.predict(X_val_word2vec)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"SVM (Word2Vec) Performance:\")\n",
    "print(classification_report(y_val, y_pred_svm))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a108ca05-a0f0-461d-a47b-69dbf77280bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM+Word2Vec LIME figure -> figures/svm_word2vec_lime/svm_w2v_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "svm_cal = CalibratedClassifierCV(estimator=svm_model, cv=5)\n",
    "svm_cal.fit(X_train_word2vec, y_train)\n",
    "class_names = [str(c) for c in svm_cal.classes_]\n",
    "\n",
    "# 1) Adapter that reuses YOUR embedding function (no new helper logic)\n",
    "emb_dim = X_train_word2vec.shape[1]\n",
    "\n",
    "def predict_proba_from_text(texts):\n",
    "    # reuse your function: it expects tokens, so pass text.split()\n",
    "    vecs = [get_word2vec_embeddings(t.split(), word2vec_model) for t in texts]\n",
    "    X = np.vstack(vecs).reshape(len(vecs), emb_dim)\n",
    "    return svm_cal.predict_proba(X)\n",
    "\n",
    "# 2) Choose one representative validation sample per class (prefer model-predicted)\n",
    "OUTDIR = Path(\"figures/svm_word2vec_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"svm_w2v_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "probas_all = predict_proba_from_text(list(X_val if hasattr(X_val, \"__iter__\") else X_val.values))\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])   # predicted as class i\n",
    "    else:\n",
    "        # fallback: first ground-truth example of class i\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# 3) Build one PNG with 5 token-importance subplots (readable words)\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[i]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        text, predict_proba_from_text, num_features=TOP_K, labels=[pred_idx]\n",
    "    )\n",
    "    pairs = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*pairs) if pairs else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved SVM+Word2Vec LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6dbad6c-941a-4df8-b55c-a94d9df8db23",
   "metadata": {},
   "source": [
    "## Logistic Regression with Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7ae6d931-cc59-45ff-b2d8-680c637eddb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (Word2Vec) Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.70      0.70       479\n",
      "           2       0.54      0.31      0.40       224\n",
      "           3       0.51      0.37      0.43       295\n",
      "           4       0.68      0.66      0.67       520\n",
      "           5       0.47      0.59      0.52       792\n",
      "\n",
      "    accuracy                           0.57      2310\n",
      "   macro avg       0.58      0.52      0.54      2310\n",
      "weighted avg       0.58      0.57      0.57      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train a Logistic Regression classifier using Word2vec embeddings\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Predict on the validatio set\n",
    "y_pred_logreg = logreg_model.predict(X_val_word2vec)\n",
    "\n",
    "# Evaluate the model's performance\n",
    "print(\"Logistic Regression (Word2Vec) Performance:\")\n",
    "print(classification_report(y_val, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7cf747e7-8454-4dd0-b4b0-286f4c225a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LR+Word2Vec LIME figure -> figures/lr_word2vec_lime/lr_w2v_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/lr_word2vec_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"lr_w2v_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "class_names = [str(c) for c in logreg_model.classes_]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "emb_dim = X_train_word2vec.shape[1]\n",
    "\n",
    "# --- Adapter: raw text -> your Word2Vec doc vector -> predict_proba\n",
    "def predict_proba_from_text(texts):\n",
    "    vecs = [get_word2vec_embeddings(t.split(), word2vec_model) for t in texts]\n",
    "    X = np.vstack(vecs).reshape(len(vecs), emb_dim)\n",
    "    return logreg_model.predict_proba(X)\n",
    "\n",
    "# --- Pick one representative validation sample per class (prefer model-predicted)\n",
    "probas_all = predict_proba_from_text(list(X_val if hasattr(X_val, \"__iter__\") else X_val.values))\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        # fallback: first ground-truth example of that class\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# --- Build and save the 5-subplot PNG\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[i]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        text, predict_proba_from_text, num_features=TOP_K, labels=[pred_idx]\n",
    "    )\n",
    "    items = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*items) if items else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved LR+Word2Vec LIME figure -> {PNG_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebf95b-ca60-4f66-91ce-bef39caf5ec4",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab7b42a-9083-41a1-8f8b-e5774bea7e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_nb_word2vec = cross_val_score(gnb_model, X_train_word2vec, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_dt_word2vec = cross_val_score(dt_model, X_train_word2vec, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_svm_word2vec = cross_val_score(svm_model, X_train_word2vec, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_logreg_word2vec = cross_val_score(logreg_model, X_train_word2vec, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"Word2Vec Cross-Validation Accuracy:\\n\"\n",
    "      f\"Naive Bayes: {cv_scores_nb_word2vec.mean():.4f}, \"\n",
    "      f\"Decision Tree: {cv_scores_dt_word2vec.mean():.4f}, \"\n",
    "      f\"SVM: {cv_scores_svm_word2vec.mean():.4f}, \"\n",
    "      f\"Logistic Regression: {cv_scores_logreg_word2vec.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af42186b-e884-47d5-8a04-f59845d78347",
   "metadata": {},
   "source": [
    "## Comparison of the result with Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fddc394e-fb23-4664-b3ce-db7454a2a5a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store model results\n",
    "results_word2vec = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision (weighted avg)': [],\n",
    "    'Recall (weighted avg)': [],\n",
    "    'F1-Score (weighted avg)': []\n",
    "}\n",
    "\n",
    "# Helper function to evaluate and store model results\n",
    "def evaluate_model_word2vec(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Get classification report\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the results\n",
    "    results_word2vec['Model'].append(model_name)\n",
    "    results_word2vec['Accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    results_word2vec['Precision (weighted avg)'].append(report['weighted avg']['precision'])\n",
    "    results_word2vec['Recall (weighted avg)'].append(report['weighted avg']['recall'])\n",
    "    results_word2vec['F1-Score (weighted avg)'].append(report['weighted avg']['f1-score'])\n",
    "\n",
    "# 1. Gaussian Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "evaluate_model_word2vec(\"Gaussian Naive Bayes\", nb_model, X_train_word2vec, y_train, X_val_word2vec, y_val)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "evaluate_model_word2vec(\"Decision Tree\", dt_model, X_train_word2vec, y_train, X_val_word2vec, y_val)\n",
    "\n",
    "# 3. Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "evaluate_model_word2vec(\"Support Vector Machine\", svm_model, X_train_word2vec, y_train, X_val_word2vec, y_val)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "logreg_model = LogisticRegression(max_iter=500, random_state=42)\n",
    "evaluate_model_word2vec(\"Logistic Regression\", logreg_model, X_train_word2vec, y_train, X_val_word2vec, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f14f304-5cb8-48c6-8d63-a5aba93cd584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results dictionary into a DataFrame\n",
    "results_df_word2vec = pd.DataFrame(results_word2vec)\n",
    "\n",
    "# Set up the figure for the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(results_df_word2vec.set_index('Model').T, annot=True, cmap='viridis', linewidths=0.5, fmt=\".2f\")\n",
    "plt.title('Comparison of Model Performance using Word2Vec Feature Representation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04fe624-4c37-4460-8a15-0aff6c1e95a9",
   "metadata": {},
   "source": [
    "# Word Embeddings (GloVe) representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf911c02-e468-4489-9712-6e4f3fdf2aed",
   "metadata": {},
   "source": [
    "GloVe creates word embeddings by analyzing the global co-occurrence of words across a corpus, while Word2Vec uses a predictive approach that learns word representations based on their local context (neighboring words). GloVe focuses on capturing global relationships between words, whereas Word2Vec relies on learning patterns through context-based predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92df9663-a088-49e2-90a0-86e1bdcc129e",
   "metadata": {},
   "source": [
    "## Load GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d8e2a-bd56-49ee-b18b-1c0240d10b56",
   "metadata": {},
   "source": [
    "They provide a way to represent words in a numerical form that can capture semantic meanings and relationships. These embeddings, which are pre-trained on large text corpora, help the machine learning models understand the context and relationships between words without needing to train embeddings from scratch. By loading GloVe embeddings, we can leverage this pre-trained knowledge to improve the performance of our models in text classification tasks like the one in your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdf74347-6eb1-4ce6-a3a9-5454d3d6eeea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_vectors(glove_file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.array(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file_path = \"GloVe-files/glove.6B.100d.txt\" \n",
    "glove_embeddings = load_glove_vectors(glove_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78abefb-7454-4d8e-80bd-185b47d379e0",
   "metadata": {},
   "source": [
    "The choice of usage of 100 dimensional GloVe vectors instead is due to the capacity to capture important information without requiring an excessive amount of computational power.\n",
    "Higher-dimensional vectors (e.g., 200d or 300d) might offer more detailed word relationships, but they also come with increased memory and processing requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e55e1ee-604c-4935-a08f-16d484380527",
   "metadata": {},
   "source": [
    "## Convert cleaned text to GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e2304d5-1172-4b7e-9a71-b3b5f6d4b8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_glove_embeddings(text, glove_embeddings, embedding_dim=100):\n",
    "    words = text.split()\n",
    "    vectors = [glove_embeddings[word] for word in words if word in glove_embeddings]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f05f38b-d2f2-4ac3-b421-d9f72e76e186",
   "metadata": {},
   "source": [
    "## Apply the GloVe embeddings to training and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10231b6e-3362-4389-9044-15bc305f6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_glove = np.vstack(X_train.apply(lambda x: get_glove_embeddings(x, glove_embeddings)))\n",
    "X_val_glove = np.vstack(X_val.apply(lambda x: get_glove_embeddings(x, glove_embeddings)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6fcdd-ea17-4058-8a0a-e3ab5cc4384c",
   "metadata": {},
   "source": [
    "## Train and evaluate the models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af00899c-f42c-4ebd-9613-6f2392128e55",
   "metadata": {},
   "source": [
    "The text has been treated in order to be compatible with the models, Naives Bayes, Decision Tree and SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8b71f9-5e1a-4bbc-8af6-5ce9df0446a7",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e584eff-b2d7-4e7b-b0af-68ce56483c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe + Gaussian Naive Bayes Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.53      0.59      0.56       479\n",
      "           2       0.28      0.26      0.27       224\n",
      "           3       0.28      0.47      0.35       295\n",
      "           4       0.46      0.56      0.51       520\n",
      "           5       0.41      0.22      0.29       792\n",
      "\n",
      "    accuracy                           0.41      2310\n",
      "   macro avg       0.39      0.42      0.40      2310\n",
      "weighted avg       0.42      0.41      0.40      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_glove, y_train)\n",
    "y_pred_gnb = gnb_model.predict(X_val_glove)\n",
    "print(\"GloVe + Gaussian Naive Bayes Performance:\")\n",
    "print(classification_report(y_val, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ff83e20-d751-4eb7-9c00-a41c404e370f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5-class LIME figure -> figures/nb_glove_lime/nb_glove_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/nb_glove_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"nb_glove_lime_5classes.png\"\n",
    "\n",
    "# -- embed raw texts to averaged GloVe vectors (same logic you used before)\n",
    "def embed_glove_texts(texts, embedding_dim=100):\n",
    "    vecs = []\n",
    "    for t in texts:\n",
    "        words = t.split()\n",
    "        wvecs = [glove_embeddings[w] for w in words if w in glove_embeddings]\n",
    "        vecs.append(np.mean(wvecs, axis=0) if wvecs else np.zeros(embedding_dim, dtype=np.float32))\n",
    "    return np.vstack(vecs)\n",
    "\n",
    "def predict_proba_glove(raw_texts):\n",
    "    X = embed_glove_texts(raw_texts, embedding_dim=100)  # change dim if needed\n",
    "    return gnb_model.predict_proba(X)\n",
    "\n",
    "class_names = [str(c) for c in gnb_model.classes_]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# -- choose one representative index per class\n",
    "probas = predict_proba_glove(list(X_val if hasattr(X_val, \"__iter__\") else X_val.values))\n",
    "pred_idxs = np.argmax(probas, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:             # prefer a sample predicted as class i\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        # fallback: first ground-truth example of this class\n",
    "        # (works if y_val is pandas Series or list)\n",
    "        try:\n",
    "            # if labels are like [1..5], map to index position\n",
    "            true_indices = [k for k, y in enumerate(list(y_val)) if str(y) == class_names[i]]\n",
    "        except Exception:\n",
    "            true_indices = []\n",
    "        chosen.append(true_indices[0] if true_indices else 0)\n",
    "\n",
    "# -- build the 5-subplot figure\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "top_k = 10\n",
    "for i, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[i]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "\n",
    "    # explain for the predicted label of this sample\n",
    "    pred_idx = int(np.argmax(predict_proba_glove([text])[0]))\n",
    "    exp = explainer.explain_instance(text, predict_proba_glove, num_features=top_k, labels=[pred_idx])\n",
    "    tok_w = exp.as_list(label=pred_idx)\n",
    "\n",
    "    terms, weights = zip(*tok_w) if tok_w else ([\"(no tokens)\"], [0.0])\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "# hide the unused 6th subplot (bottom-right)\n",
    "axes[-1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved 5-class LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a25d41e9-eed4-4b10-a509-1aedd2cbe677",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dd0c03d1-aeb2-4810-926f-8a2bbf921a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe + Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.35      0.40      0.38       479\n",
      "           2       0.06      0.08      0.07       224\n",
      "           3       0.14      0.18      0.16       295\n",
      "           4       0.31      0.27      0.29       520\n",
      "           5       0.23      0.18      0.20       792\n",
      "\n",
      "    accuracy                           0.24      2310\n",
      "   macro avg       0.22      0.22      0.22      2310\n",
      "weighted avg       0.25      0.24      0.24      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_glove, y_train)\n",
    "y_pred_dt = dt_model.predict(X_val_glove)\n",
    "print(\"GloVe + Decision Tree Performance:\")\n",
    "print(classification_report(y_val, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c9364cd6-27cf-494e-a369-8c50e031995d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/dt_glove/dt_glove_tree.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/dt_glove\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Train a small interpretable tree\n",
    "dt_shallow = DecisionTreeClassifier(\n",
    "    max_depth=3, min_samples_split=20, min_samples_leaf=10, random_state=42\n",
    ")\n",
    "dt_shallow.fit(X_train_glove, y_train)\n",
    "\n",
    "# Names\n",
    "d = X_train_glove.shape[1]\n",
    "feat_names = [f\"glove_dim_{i}\" for i in range(d)]\n",
    "class_names = [str(c) for c in dt_shallow.classes_]\n",
    "\n",
    "# Plot & save\n",
    "plt.figure(figsize=(14, 10))\n",
    "plot_tree(\n",
    "    dt_shallow,\n",
    "    feature_names=feat_names,\n",
    "    class_names=class_names,\n",
    "    filled=True,\n",
    "    rounded=True,\n",
    "    impurity=True,\n",
    "    proportion=True,\n",
    "    fontsize=9,\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTDIR / \"dt_glove_tree.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved:\", OUTDIR / \"dt_glove_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e8f3563-dfca-4d3a-b8e2-d214f95abcb0",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "dbbe9229-892d-4f16-aa1e-6be27054c5f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe + Support Vector Machine Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.68      0.64       479\n",
      "           2       0.11      0.00      0.01       224\n",
      "           3       0.56      0.20      0.30       295\n",
      "           4       0.59      0.54      0.57       520\n",
      "           5       0.43      0.65      0.52       792\n",
      "\n",
      "    accuracy                           0.51      2310\n",
      "   macro avg       0.46      0.41      0.41      2310\n",
      "weighted avg       0.49      0.51      0.48      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_glove, y_train)\n",
    "y_pred_svm = svm_model.predict(X_val_glove)\n",
    "print(\"GloVe + Support Vector Machine Performance:\")\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10cd4d35-d9f0-4e6f-84f0-0eba22d37793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM+GloVe LIME figure -> figures/svm_glove_lime/svm_glove_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "svm_cal = CalibratedClassifierCV(estimator=svm_model, cv=5)  # use 'estimator' on sklearn >=1.2\n",
    "svm_cal.fit(X_train_glove, y_train)\n",
    "class_names = [str(c) for c in svm_cal.classes_]\n",
    "\n",
    "# 1) Adapter: raw text -> your GloVe doc vector -> predict_proba\n",
    "emb_dim = X_train_glove.shape[1]\n",
    "\n",
    "def predict_proba_from_text(texts):\n",
    "    vecs = [get_glove_embeddings(t, glove_embeddings, embedding_dim=emb_dim) for t in texts]\n",
    "    X = np.vstack(vecs).reshape(len(vecs), emb_dim)\n",
    "    return svm_cal.predict_proba(X)\n",
    "\n",
    "# 2) Pick one representative validation sample per class (prefer ones predicted as that class)\n",
    "OUTDIR = Path(\"figures/svm_glove_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"svm_glove_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "raw_val = list(X_val if hasattr(X_val, \"__iter__\") else X_val.values)\n",
    "probas_all = predict_proba_from_text(raw_val)\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])    # sample predicted as class i\n",
    "    else:\n",
    "        # fallback: first ground-truth example of class i\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# 3) Build & save the 5-panel PNG\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=( Twelve := 12, Ten := 10 ))  # small trick to keep style\n",
    "axes = axes.ravel()\n",
    "\n",
    "for k, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[k]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(text, predict_proba_from_text, num_features=TOP_K, labels=[pred_idx])\n",
    "    pairs = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*pairs) if pairs else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved SVM+GloVe LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74940ba9-b68f-41ed-a6a4-8053a67dd87c",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1fe66fd7-48cb-4af7-860c-13cc0cdd6721",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GloVe + Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.63      0.66      0.64       479\n",
      "           2       0.45      0.22      0.29       224\n",
      "           3       0.49      0.30      0.37       295\n",
      "           4       0.58      0.55      0.57       520\n",
      "           5       0.44      0.57      0.49       792\n",
      "\n",
      "    accuracy                           0.51      2310\n",
      "   macro avg       0.52      0.46      0.47      2310\n",
      "weighted avg       0.52      0.51      0.51      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_model = LogisticRegression(max_iter=1000, random_state = 42)\n",
    "logreg_model.fit(X_train_glove, y_train)\n",
    "y_pred_logreg = logreg_model.predict(X_val_glove)\n",
    "print(\"GloVe + Logistic Regression Performance:\")\n",
    "print(classification_report(y_val, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "a608d336-bbc3-4f90-9006-f59e7a2c4c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LR+GloVe LIME figure -> figures/lr_glove_lime/lr_glove_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/lr_glove_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"lr_glove_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "class_names = [str(c) for c in logreg_model.classes_]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "emb_dim = X_train_glove.shape[1]\n",
    "\n",
    "# Adapter: raw text -> your GloVe doc vector -> predict_proba\n",
    "def predict_proba_from_text(texts):\n",
    "    vecs = [get_glove_embeddings(t, glove_embeddings, embedding_dim=emb_dim) for t in texts]\n",
    "    X = np.vstack(vecs).reshape(len(vecs), emb_dim)\n",
    "    return logreg_model.predict_proba(X)\n",
    "\n",
    "# Pick one representative validation sample per class (prefer model-predicted examples)\n",
    "raw_val = list(X_val if hasattr(X_val, \"__iter__\") else X_val.values)\n",
    "probas_all = predict_proba_from_text(raw_val)\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        # fallback to first ground-truth example of that class\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# Build & save the 5-panel PNG\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for k, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[k]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(text, predict_proba_from_text, num_features=TOP_K, labels=[pred_idx])\n",
    "    items = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*items) if items else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved LR+GloVe LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e1e32f-d1f2-4916-af11-23447d5761a7",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71b6d6-217e-4300-bd77-0d081212e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_nb_glove = cross_val_score(gnb_model, X_train_glove, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_dt_glove = cross_val_score(dt_model, X_train_glove, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_svm_glove = cross_val_score(svm_model, X_train_glove, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_logreg_glove = cross_val_score(logreg_model, X_train_glove, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"GloVe Cross-Validation Accuracy:\\n\"\n",
    "      f\"Naive Bayes: {cv_scores_nb_glove.mean():.4f}, \"\n",
    "      f\"Decision Tree: {cv_scores_dt_glove.mean():.4f}, \"\n",
    "      f\"SVM: {cv_scores_svm_glove.mean():.4f}, \"\n",
    "      f\"Logistic Regression: {cv_scores_logreg_glove.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585bd06b-e9b1-4c65-a75e-0388d7cb538a",
   "metadata": {},
   "source": [
    "## Comparison of results with GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42dba394-4a2e-49ba-bebf-e4c7ac93cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store GloVe model results\n",
    "results_glove = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision (weighted avg)': [],\n",
    "    'Recall (weighted avg)': [],\n",
    "    'F1-Score (weighted avg)': []\n",
    "}\n",
    "\n",
    "# Helper function to evaluate and store GloVe model results\n",
    "def evaluate_model_glove(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Get classification report\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the results\n",
    "    results_glove['Model'].append(model_name)\n",
    "    results_glove['Accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    results_glove['Precision (weighted avg)'].append(report['weighted avg']['precision'])\n",
    "    results_glove['Recall (weighted avg)'].append(report['weighted avg']['recall'])\n",
    "    results_glove['F1-Score (weighted avg)'].append(report['weighted avg']['f1-score'])\n",
    "\n",
    "# 1. Gaussian Naive Bayes\n",
    "nb_model = GaussianNB()\n",
    "evaluate_model_glove(\"Gaussian Naive Bayes\", nb_model, X_train_glove, y_train, X_val_glove, y_val)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "evaluate_model_glove(\"Decision Tree\", dt_model, X_train_glove, y_train, X_val_glove, y_val)\n",
    "\n",
    "# 3. Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "evaluate_model_glove(\"Support Vector Machine\", svm_model, X_train_glove, y_train, X_val_glove, y_val)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "logreg_model = LogisticRegression(max_iter = 1000, random_state = 42)\n",
    "evaluate_model_glove(\"Logistic Regression\", logreg_model, X_train_glove, y_train, X_val_glove, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d639601-4478-44ff-b2af-06602344e87e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the results dictionary into a DataFrame\n",
    "results_df_glove = pd.DataFrame(results_glove)\n",
    "\n",
    "# Set up the figure for the heatmap\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(results_df_glove.set_index('Model').T, annot=True, cmap='viridis', linewidths=0.5, fmt=\".2f\")\n",
    "plt.title('Comparison of Model Performance using GloVe Feature Representation')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4befb1c9-9bfe-4ac8-ab5a-285f36b5b0bc",
   "metadata": {},
   "source": [
    "# SBERT model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf88210-8283-42c9-b27a-c2542e7d8214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install sentence-transformers\n",
    "# pip install ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca0b080-3275-4293-afa5-88abf90801bc",
   "metadata": {},
   "source": [
    "### Import SBERT and Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "018fe317-2a5e-4587-b93c-76f16c56186a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6992702e74944e53980cd645ed666281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load a pre-trained SBERT model\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64aa4540-0873-4237-9283-aa5e44b38243",
   "metadata": {},
   "source": [
    "## Generating Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c70e5d-40c4-4dea-8703-c2d5fed1ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sentence embeddings for the training and validation sets\n",
    "X_train_embeddings = sbert_model.encode(X_train.tolist(), convert_to_tensor=True)\n",
    "X_val_embeddings = sbert_model.encode(X_val.tolist(), convert_to_tensor=True)\n",
    "\n",
    "# Convert embeddings to numpy arrays (optional)\n",
    "X_train_embeddings = X_train_embeddings.cpu().numpy()\n",
    "X_val_embeddings = X_val_embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bb2077-5883-42ed-b5b2-ae1b2014273c",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14a991ba-c2b7-4a50-9482-803db0b2883b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "89361464-8167-4ec3-804e-b01b90559d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + Gaussian Naive Bayes Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.70      0.79      0.74       479\n",
      "           2       0.46      0.67      0.55       224\n",
      "           3       0.48      0.62      0.54       295\n",
      "           4       0.63      0.81      0.71       520\n",
      "           5       0.58      0.29      0.38       792\n",
      "\n",
      "    accuracy                           0.59      2310\n",
      "   macro avg       0.57      0.64      0.59      2310\n",
      "weighted avg       0.59      0.59      0.57      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Gaussian Naive Bayes using SBERT embeddings\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_gnb = gnb_model.predict(X_val_embeddings)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"SBERT + Gaussian Naive Bayes Performance:\")\n",
    "print(classification_report(y_val, y_pred_gnb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e15c6fa5-c316-4ac2-bf81-e5a80d89b0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 5-class LIME figure -> figures/nb_sbert_lime/nb_sbert_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "OUTDIR = Path(\"figures/nb_sbert_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"nb_sbert_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "# 1) Embed raw texts with your existing SBERT model\n",
    "def embed_sbert(texts):\n",
    "    # Use your same model; returns np.ndarray [n, d]\n",
    "    return sbert_model.encode(list(texts), convert_to_numpy=True)\n",
    "\n",
    "# 2) Predict-proba wrapper for LIME (raw text -> proba)\n",
    "def predict_proba_sbert(raw_texts):\n",
    "    X = embed_sbert(raw_texts)\n",
    "    return gnb_model.predict_proba(X)\n",
    "\n",
    "class_names = [str(c) for c in gnb_model.classes_]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# 3) Choose one representative sample per class\n",
    "probas = predict_proba_sbert(list(X_val if hasattr(X_val, \"__iter__\") else X_val.values))\n",
    "pred_idxs = np.argmax(probas, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "# prefer a sample predicted as that class; fallback to first ground-truth of that class\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# 4) Build the 5-subplot figure\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[i]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "\n",
    "    # explain for the predicted label of this sample\n",
    "    pred_idx = int(np.argmax(predict_proba_sbert([text])[0]))\n",
    "    exp = explainer.explain_instance(text, predict_proba_sbert, num_features=TOP_K, labels=[pred_idx])\n",
    "    tok_w = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*tok_w) if tok_w else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")  # hide empty 6th tile\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved 5-class LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b223f5-0092-46d4-b0a7-a8b053848fdb",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "5c4a17b3-2c4b-4277-b002-edc9f8fe24d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.79      0.75       479\n",
      "           2       0.55      0.49      0.52       224\n",
      "           3       0.57      0.48      0.52       295\n",
      "           4       0.69      0.76      0.72       520\n",
      "           5       0.56      0.54      0.55       792\n",
      "\n",
      "    accuracy                           0.63      2310\n",
      "   macro avg       0.62      0.61      0.61      2310\n",
      "weighted avg       0.62      0.63      0.62      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression using SBERT embeddings\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_logreg = logreg_model.predict(X_val_embeddings)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"SBERT + Logistic Regression Performance:\")\n",
    "print(classification_report(y_val, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0c1f9b0f-d791-4f39-a76f-4a2c35e45d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved LR+SBERT LIME figure -> figures/lr_sbert_lime/lr_sbert_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/lr_sbert_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"lr_sbert_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "class_names = [str(c) for c in logreg_model.classes_]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "emb_dim = X_train_embeddings.shape[1]\n",
    "\n",
    "# Adapter: raw text -> SBERT embedding -> predict_proba\n",
    "def predict_proba_from_text(texts):\n",
    "    # SBERT encode returns numpy if convert_to_tensor=False\n",
    "    X = sbert_model.encode(list(texts), convert_to_tensor=False, batch_size=64, show_progress_bar=False)\n",
    "    X = np.asarray(X).reshape(len(texts), emb_dim)\n",
    "    return logreg_model.predict_proba(X)\n",
    "\n",
    "# Choose one representative validation sample per class (prefer model-predicted)\n",
    "raw_val = list(X_val if hasattr(X_val, \"__iter__\") else X_val.values)\n",
    "probas_all = predict_proba_from_text(raw_val)\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        # fallback: first ground-truth example of that class\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# Build & save the 5-panel PNG\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for k, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[k]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        text, predict_proba_from_text, num_features=TOP_K, labels=[pred_idx]\n",
    "    )\n",
    "    items = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*items) if items else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved LR+SBERT LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cbe2e93-c874-40a4-8eea-774555d9170d",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "fba2ae9c-af67-4e8f-8be2-1695004f9431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.82      0.76       479\n",
      "           2       0.55      0.54      0.54       224\n",
      "           3       0.55      0.47      0.51       295\n",
      "           4       0.68      0.79      0.73       520\n",
      "           5       0.57      0.49      0.53       792\n",
      "\n",
      "    accuracy                           0.63      2310\n",
      "   macro avg       0.61      0.62      0.61      2310\n",
      "weighted avg       0.62      0.63      0.62      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM using SBERT embeddings\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_svm = svm_model.predict(X_val_embeddings)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"SBERT + SVM Performance:\")\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f73bc358-38d6-4889-8ec3-f5c967fa4d20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM+SBERT LIME figure -> figures/svm_sbert_lime/svm_sbert_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "svm_cal = CalibratedClassifierCV(estimator=svm_model, cv=5)  # use 'estimator' on sklearn >=1.2\n",
    "svm_cal.fit(X_train_embeddings, y_train)\n",
    "class_names = [str(c) for c in svm_cal.classes_]\n",
    "\n",
    "OUTDIR = Path(\"figures/svm_sbert_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"svm_sbert_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "emb_dim = X_train_embeddings.shape[1]\n",
    "\n",
    "# 1) Adapter: raw text -> SBERT embedding -> predict_proba\n",
    "def predict_proba_from_text(texts):\n",
    "    X = sbert_model.encode(list(texts), convert_to_tensor=False, batch_size=64, show_progress_bar=False)\n",
    "    X = np.asarray(X).reshape(len(texts), emb_dim)\n",
    "    return svm_cal.predict_proba(X)\n",
    "\n",
    "# 2) Pick one representative validation sample per class (prefer model-predicted)\n",
    "raw_val = list(X_val if hasattr(X_val, \"__iter__\") else X_val.values)\n",
    "probas_all = predict_proba_from_text(raw_val)\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])    # predicted as that class\n",
    "    else:\n",
    "        # fallback: first ground-truth example of that class\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# 3) Build and save the 5-panel PNG\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for k, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[k]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(\n",
    "        text, predict_proba_from_text, num_features=TOP_K, labels=[pred_idx]\n",
    "    )\n",
    "    items = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*items) if items else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved SVM+SBERT LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c425c35-4d01-43e7-847e-b9450cdd5180",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3909769e-f2b5-433e-b9fc-1dc3035759bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SBERT + Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.48      0.55      0.51       479\n",
      "           2       0.19      0.23      0.21       224\n",
      "           3       0.18      0.20      0.19       295\n",
      "           4       0.47      0.45      0.46       520\n",
      "           5       0.29      0.24      0.26       792\n",
      "\n",
      "    accuracy                           0.35      2310\n",
      "   macro avg       0.32      0.34      0.33      2310\n",
      "weighted avg       0.35      0.35      0.35      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree using SBERT embeddings\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_dt = dt_model.predict(X_val_embeddings)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"SBERT + Decision Tree Performance:\")\n",
    "print(classification_report(y_val, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "56ab8789-90fc-4250-8950-8d1e1f263a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/dt_sbert/dt_sbert_tree.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/dt_sbert\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Train a compact tree for visualization (keep your full model for metrics if you want)\n",
    "dt_shallow = DecisionTreeClassifier(\n",
    "    max_depth=3, min_samples_split=20, min_samples_leaf=10, random_state=42\n",
    ")\n",
    "dt_shallow.fit(X_train_embeddings, y_train)\n",
    "\n",
    "feat_names  = [f\"sbert_dim_{i}\" for i in range(X_train_embeddings.shape[1])]\n",
    "class_names = [str(c) for c in dt_shallow.classes_]\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "plot_tree(\n",
    "    dt_shallow,\n",
    "    feature_names=feat_names,\n",
    "    class_names=class_names,\n",
    "    filled=True, rounded=True,\n",
    "    impurity=True, proportion=True,\n",
    "    fontsize=9\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTDIR / \"dt_sbert_tree.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved:\", OUTDIR / \"dt_sbert_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb8176-8f60-4584-90e4-fa45d6a03e78",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c7a433-bee6-46d4-a290-08e0c0bfa60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_nb_sbert = cross_val_score(gnb_model, X_train_embeddings, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_dt_sbert = cross_val_score(dt_model, X_train_embeddings, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_svm_sbert = cross_val_score(svm_model, X_train_embeddings, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "cv_scores_logreg_sbert = cross_val_score(logreg_model, X_train_embeddings, y_train, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(\"SBERT Cross-Validation Accuracy:\\n\"\n",
    "      f\"Naive Bayes: {cv_scores_nb_sbert.mean():.4f}, \"\n",
    "      f\"Decision Tree: {cv_scores_dt_sbert.mean():.4f}, \"\n",
    "      f\"SVM: {cv_scores_svm_sbert.mean():.4f}, \"\n",
    "      f\"Logistic Regression: {cv_scores_logreg_sbert.mean():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93930ad7-ee22-4ef5-9121-9048845a773b",
   "metadata": {},
   "source": [
    "## Comparison of result with sentence embedding (SBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd584417-00ad-45d3-9b03-1b9f40f84a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store SBERT model results\n",
    "results_sbert = {\n",
    "    'Model': [],\n",
    "    'Accuracy': [],\n",
    "    'Precision (weighted avg)': [],\n",
    "    'Recall (weighted avg)': [],\n",
    "    'F1-Score (weighted avg)': []\n",
    "}\n",
    "\n",
    "# Helper function to evaluate and store SBERT model results\n",
    "def evaluate_model_sbert(model_name, model, X_train, y_train, X_val, y_val):\n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict on validation set\n",
    "    y_pred = model.predict(X_val)\n",
    "    \n",
    "    # Get classification report\n",
    "    report = classification_report(y_val, y_pred, output_dict=True)\n",
    "    \n",
    "    # Store the results\n",
    "    results_sbert['Model'].append(model_name)\n",
    "    results_sbert['Accuracy'].append(accuracy_score(y_val, y_pred))\n",
    "    results_sbert['Precision (weighted avg)'].append(report['weighted avg']['precision'])\n",
    "    results_sbert['Recall (weighted avg)'].append(report['weighted avg']['recall'])\n",
    "    results_sbert['F1-Score (weighted avg)'].append(report['weighted avg']['f1-score'])\n",
    "\n",
    "# 1. Gaussian Naive Bayes\n",
    "gnb_model = GaussianNB()\n",
    "evaluate_model_sbert(\"Gaussian Naive Bayes\", gnb_model, X_train_embeddings, y_train, X_val_embeddings, y_val)\n",
    "\n",
    "# 2. Decision Tree\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "evaluate_model_sbert(\"Decision Tree\", dt_model, X_train_embeddings, y_train, X_val_embeddings, y_val)\n",
    "\n",
    "# 3. Support Vector Machine (SVM)\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "evaluate_model_sbert(\"Support Vector Machine\", svm_model, X_train_embeddings, y_train, X_val_embeddings, y_val)\n",
    "\n",
    "# 4. Logistic Regression\n",
    "logreg_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "evaluate_model_sbert(\"Logistic Regression\", logreg_model, X_train_embeddings, y_train, X_val_embeddings, y_val)\n",
    "\n",
    "# Convert results dictionary to DataFrame\n",
    "results_df_sbert = pd.DataFrame(results_sbert)\n",
    "\n",
    "# Heatmap of results\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.heatmap(results_df_sbert.set_index('Model').T, annot=True, cmap='viridis', linewidths=0.5, fmt=\".2f\")\n",
    "plt.title('Comparison of Model Performance with SBERT Embeddings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36215aff-544e-4a01-a9f1-2cbba7d59e10",
   "metadata": {},
   "source": [
    "# BioBERT model implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48627d8-1b6c-4f34-b4b0-36d7e4cb206c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff15f91a-0922-451e-8c88-a1807ec5aefa",
   "metadata": {},
   "source": [
    "### Import BioBERT and Load Pre-trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3fc1b9f2-0b41-4f37-906e-fb5c7891e09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")\n",
    "model = AutoModel.from_pretrained(\"dmis-lab/biobert-base-cased-v1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c95f06-ebef-4d4c-8d06-bfcc27a644cd",
   "metadata": {},
   "source": [
    "### Generating Sentence Embeddings and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a92876fe-a9d7-4e04-8a78-1e7e058d4eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_biobert_embeddings(text_list, tokenizer, model):\n",
    "    embeddings = []\n",
    "    for text in text_list:\n",
    "        # Tokenize the text and generate inputs\n",
    "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "        # Pass inputs through the BioBERT model\n",
    "        with torch.no_grad():  # Disable gradient calculation\n",
    "            outputs = model(**inputs)\n",
    "        # Extract CLS token embeddings (first token)\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()\n",
    "        embeddings.append(cls_embedding)\n",
    "    return np.array(embeddings)\n",
    "\n",
    "# Generate embeddings for training and validation sets\n",
    "X_train_biobert = get_biobert_embeddings(X_train.tolist(), tokenizer, model)\n",
    "X_val_biobert = get_biobert_embeddings(X_val.tolist(), tokenizer, model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7df6aba-c882-43fe-9b35-928f1f130c65",
   "metadata": {},
   "source": [
    "## Train and Evaluate Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6c3eec-28ea-4f73-999f-372f542999d3",
   "metadata": {},
   "source": [
    "### Naives Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "16061a3e-b499-4742-8c84-fd75fe95a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioBERT + Gaussian Naive Bayes Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.53      0.58       479\n",
      "           2       0.36      0.44      0.40       224\n",
      "           3       0.28      0.54      0.37       295\n",
      "           4       0.41      0.67      0.51       520\n",
      "           5       0.48      0.14      0.22       792\n",
      "\n",
      "    accuracy                           0.42      2310\n",
      "   macro avg       0.44      0.46      0.41      2310\n",
      "weighted avg       0.46      0.42      0.40      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Gaussian Naive Bayes using BioBERT embeddings\n",
    "gnb_model = GaussianNB()\n",
    "gnb_model.fit(X_train_biobert, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_gnb = gnb_model.predict(X_val_biobert)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"BioBERT + Gaussian Naive Bayes Performance:\")\n",
    "print(classification_report(y_val, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af70a1db-e961-4e2f-8f8f-db4f32dbe60c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved BioBERT LIME figure -> figures/nb_biobert_lime/nb_biobert_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/nb_biobert_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"nb_biobert_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "# 1) Predict-proba wrapper (raw text -> BioBERT embeddings -> NB proba)\n",
    "def predict_proba_biobert(raw_texts):\n",
    "    X = get_biobert_embeddings(list(raw_texts), tokenizer, model)  # uses your function\n",
    "    return gnb_model.predict_proba(X)\n",
    "\n",
    "class_names = [str(c) for c in gnb_model.classes_]\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "\n",
    "# 2) Choose one representative validation sample per class\n",
    "probas = predict_proba_biobert(list(X_val if hasattr(X_val, \"__iter__\") else X_val.values))\n",
    "pred_idxs = np.argmax(probas, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:                     # prefer a sample predicted as class i\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        # fallback: first ground-truth example of this class (string compare is robust)\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# 3) Build the 5-subplot figure\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[i]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "\n",
    "    pred_idx = int(np.argmax(predict_proba_biobert([text])[0]))\n",
    "    exp = explainer.explain_instance(text, predict_proba_biobert, num_features=TOP_K, labels=[pred_idx])\n",
    "    tok_w = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*tok_w) if tok_w else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")  # hide empty 6th tile\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved BioBERT LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49233566-2778-4c26-a294-717594debef1",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "426a274a-353f-454e-b463-01a705928493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioBERT + Decision Tree Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.34      0.38      0.36       479\n",
      "           2       0.11      0.14      0.12       224\n",
      "           3       0.11      0.13      0.12       295\n",
      "           4       0.32      0.32      0.32       520\n",
      "           5       0.20      0.16      0.18       792\n",
      "\n",
      "    accuracy                           0.23      2310\n",
      "   macro avg       0.22      0.22      0.22      2310\n",
      "weighted avg       0.23      0.23      0.23      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Decision Tree using BioBERT embeddings\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train_biobert, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_dt = dt_model.predict(X_val_biobert)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"BioBERT + Decision Tree Performance:\")\n",
    "print(classification_report(y_val, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "5d3922b3-0aa0-4bf6-8e99-fcd75d29e03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: figures/dt_biobert/dt_biobert_tree.png\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/dt_biobert\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Compact, interpretable tree (keep your full dt_model for metrics if you want)\n",
    "dt_shallow = DecisionTreeClassifier(\n",
    "    max_depth=3, min_samples_split=20, min_samples_leaf=10, random_state=42\n",
    ")\n",
    "dt_shallow.fit(X_train_biobert, y_train)\n",
    "\n",
    "feat_names  = [f\"biobert_dim_{i}\" for i in range(X_train_biobert.shape[1])]\n",
    "class_names = [str(c) for c in dt_shallow.classes_]\n",
    "\n",
    "plt.figure(figsize=(14,10))\n",
    "plot_tree(\n",
    "    dt_shallow,\n",
    "    feature_names=feat_names,\n",
    "    class_names=class_names,\n",
    "    filled=True, rounded=True,\n",
    "    impurity=True, proportion=True,\n",
    "    fontsize=9\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTDIR / \"dt_biobert_tree.png\", dpi=300)\n",
    "plt.close()\n",
    "print(\"Saved:\", OUTDIR / \"dt_biobert_tree.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f835da5-0630-45ab-9972-f26d3c31e40f",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6aa928c4-3011-4ab0-9316-b363faaa5cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioBERT + Logistic Regression Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.73      0.71       479\n",
      "           2       0.48      0.45      0.46       224\n",
      "           3       0.45      0.43      0.44       295\n",
      "           4       0.66      0.65      0.65       520\n",
      "           5       0.46      0.46      0.46       792\n",
      "\n",
      "    accuracy                           0.56      2310\n",
      "   macro avg       0.55      0.54      0.55      2310\n",
      "weighted avg       0.55      0.56      0.55      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Logistic Regression using BioBERT embeddings\n",
    "logreg_model = LogisticRegression(max_iter=1500, random_state=42)\n",
    "logreg_model.fit(X_train_biobert, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_logreg = logreg_model.predict(X_val_biobert)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"BioBERT + Logistic Regression Performance:\")\n",
    "print(classification_report(y_val, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38823124-f040-4444-9580-d37d0a3383ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved coefficient plots in: figures/logreg_biobert\n"
     ]
    }
   ],
   "source": [
    "OUTDIR = Path(\"figures/logreg_biobert\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "feature_names = [f\"biobert_dim_{i}\" for i in range(X_train_biobert.shape[1])]\n",
    "class_names   = [str(c) for c in logreg_model.classes_]\n",
    "\n",
    "def plot_logreg_class_weights(class_idx, top_k=10):\n",
    "    coefs = logreg_model.coef_[class_idx]\n",
    "    top_pos = np.argsort(coefs)[-top_k:]\n",
    "    top_neg = np.argsort(coefs)[:top_k]\n",
    "    top_features = np.hstack([top_neg, top_pos])\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    colors = [\"red\" if c < 0 else \"blue\" for c in coefs[top_features]]\n",
    "    plt.barh(np.array(feature_names)[top_features], coefs[top_features], color=colors)\n",
    "    plt.title(f\"LogReg (BioBERT) – Class {class_names[class_idx]}\")\n",
    "    plt.xlabel(\"Coefficient\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / f\"logreg_biobert_class{class_names[class_idx]}.png\", dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "for c in range(len(class_names)):\n",
    "    plot_logreg_class_weights(c)\n",
    "\n",
    "print(\"Saved coefficient plots in:\", OUTDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2d326a-e801-48ca-aade-ffebc2281c29",
   "metadata": {},
   "source": [
    "### SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "54d8963d-2b7b-4bec-9a35-2184a226b0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BioBERT + SVM Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.75      0.70       479\n",
      "           2       0.44      0.43      0.44       224\n",
      "           3       0.44      0.43      0.43       295\n",
      "           4       0.64      0.66      0.65       520\n",
      "           5       0.45      0.41      0.43       792\n",
      "\n",
      "    accuracy                           0.54      2310\n",
      "   macro avg       0.53      0.54      0.53      2310\n",
      "weighted avg       0.53      0.54      0.54      2310\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train SVM using BioBERT embeddings\n",
    "svm_model = SVC(kernel='linear', random_state=42)\n",
    "svm_model.fit(X_train_biobert, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "y_pred_svm = svm_model.predict(X_val_biobert)\n",
    "\n",
    "# Evaluate performance\n",
    "print(\"BioBERT + SVM Performance:\")\n",
    "print(classification_report(y_val, y_pred_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6b492449-b776-4feb-a276-500e15161bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved SVM+BioBERT LIME figure -> figures/svm_biobert_lime/svm_biobert_lime_5classes.png\n"
     ]
    }
   ],
   "source": [
    "svm_cal = CalibratedClassifierCV(estimator=svm_model, cv=5)   # use 'estimator' on sklearn >=1.2\n",
    "svm_cal.fit(X_train_biobert, y_train)\n",
    "class_names = [str(c) for c in svm_cal.classes_]\n",
    "\n",
    "OUTDIR = Path(\"figures/svm_biobert_lime\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "PNG_PATH = OUTDIR / \"svm_biobert_lime_5classes.png\"\n",
    "TOP_K = 10\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=class_names)\n",
    "emb_dim = X_train_biobert.shape[1]\n",
    "\n",
    "# 1) Adapter: raw text -> BioBERT CLS embedding -> predict_proba\n",
    "def predict_proba_from_text(texts):\n",
    "    X = get_biobert_embeddings(list(texts), tokenizer, model)\n",
    "    X = np.asarray(X).reshape(len(texts), emb_dim)\n",
    "    return svm_cal.predict_proba(X)\n",
    "\n",
    "# 2) Pick one representative validation sample per class (prefer model-predicted)\n",
    "raw_val = list(X_val if hasattr(X_val, \"__iter__\") else X_val.values)\n",
    "probas_all = predict_proba_from_text(raw_val)\n",
    "pred_idxs = np.argmax(probas_all, axis=1)\n",
    "\n",
    "indices_by_class = {i: [] for i in range(len(class_names))}\n",
    "for idx, p in enumerate(pred_idxs):\n",
    "    indices_by_class[p].append(idx)\n",
    "\n",
    "y_list = list(y_val)\n",
    "chosen = []\n",
    "for i in range(len(class_names)):\n",
    "    if indices_by_class[i]:\n",
    "        chosen.append(indices_by_class[i][0])\n",
    "    else:\n",
    "        # fallback: first ground-truth example of that class\n",
    "        try:\n",
    "            j = next(k for k, y in enumerate(y_list) if str(y) == class_names[i])\n",
    "        except StopIteration:\n",
    "            j = 0\n",
    "        chosen.append(j)\n",
    "\n",
    "# 3) Build & save the 5-panel PNG\n",
    "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(12, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for k, ax in enumerate(axes[:5]):\n",
    "    idx = chosen[k]\n",
    "    text = X_val.iloc[idx] if hasattr(X_val, \"iloc\") else X_val[idx]\n",
    "    pred_idx = int(np.argmax(predict_proba_from_text([text])[0]))\n",
    "\n",
    "    exp = explainer.explain_instance(text, predict_proba_from_text, num_features=TOP_K,  labels=[pred_idx])\n",
    "    items = exp.as_list(label=pred_idx)\n",
    "    terms, weights = zip(*items) if items else ([\"(no tokens)\"], [0.0])\n",
    "\n",
    "    ax.barh(list(terms)[::-1], list(weights)[::-1])\n",
    "    ax.set_title(f\"Class {class_names[pred_idx]} — sample {idx}\")\n",
    "    ax.set_xlabel(\"LIME weight\")\n",
    "\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(PNG_PATH, dpi=300)\n",
    "plt.close()\n",
    "print(f\"Saved SVM+BioBERT LIME figure -> {PNG_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d9e735-10e1-44ce-a5c2-6d6c4c1b278b",
   "metadata": {},
   "source": [
    "## Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5651882a-864a-4a93-a82d-9ff97bd0b8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores_nb_biobert = cross_val_score(gnb_model, X_train_biobert, y_train, cv=5, scoring='accuracy')\n",
    "cv_scores_dt_biobert = cross_val_score(dt_model, X_train_biobert, y_train, cv=5, scoring='accuracy')\n",
    "cv_scores_svm_biobert = cross_val_score(svm_model, X_train_biobert, y_train, cv=5, scoring='accuracy')\n",
    "cv_scores_logreg_biobert = cross_val_score(logreg_model, X_train_biobert, y_train, cv=5, scoring='accuracy')\n",
    "print(\"BioBERT Cross-Validation Accuracy:\\n\"\n",
    "      f\"Naive Bayes: {cv_scores_nb_biobert.mean():.4f}, \"\n",
    "      f\"Decision Tree: {cv_scores_dt_biobert.mean():.4f}, \"\n",
    "      f\"SVM: {cv_scores_svm_biobert.mean():.4f}, \"\n",
    "      f\"Logistic Regression: {cv_scores_logreg_biobert.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55de6766-40d9-415f-8f84-12da3c48f1cf",
   "metadata": {},
   "source": [
    "## Comparison of result with sentence embedding (BioBERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af937bb6-584c-466a-b44a-27d8477007f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model names and metrics\n",
    "models = [\"Gaussian Naive Bayes\", \"Decision Tree\", \"Support Vector Machine\", \"Logistic Regression\"]\n",
    "metrics = [\"Accuracy\", \"Precision (weighted avg)\", \"Recall (weighted avg)\", \"F1-Score (weighted avg)\"]\n",
    "\n",
    "\n",
    "biobert_results = np.array([\n",
    "    [0.66, 0.34, 0.69, 0.66],  # Accuracy\n",
    "    [0.46, 0.22, 0.55, 0.53],  # Precision\n",
    "    [0.40, 0.23, 0.54, 0.54],  # Recall\n",
    "    [0.40, 0.23, 0.55, 0.54]   # F1-Score\n",
    "])\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.heatmap(biobert_results, annot=True, cmap=\"viridis\", xticklabels=models, yticklabels=metrics, cbar=True)\n",
    "plt.title(\"Comparison of Model Performance with BioBERT Embeddings\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.ylabel(\"Metric\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
